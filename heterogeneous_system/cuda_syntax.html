<!DOCTYPE html>
<html lang="zh">
<head>
  <meta charset="UTF-8">
  <title>CUDA C 重要语法科普介绍</title>
  <style>
    body { font-family: Arial, sans-serif; line-height: 1.8; margin: 40px; background: #fdfdfd; color: #333; }
    h1, h2, h3 { color: #007acc; }
    code, pre { background: #f4f4f4; padding: 4px 6px; border-radius: 4px; font-family: Consolas, monospace; }
    pre { padding: 10px; overflow-x: auto; }
    table { border-collapse: collapse; width: 100%; margin: 12px 0; }
    th, td { border: 1px solid #ccc; padding: 8px; text-align: left; }
    th { background: #f0f0f0; }
  </style>
</head>
<body>

  <h1>CUDA C 重要语法科普介绍</h1>

  <h2>一、CUDA C 架构简介</h2>
  <p>CUDA 是 NVIDIA 推出的并行计算平台和编程模型。CUDA C 程序包含两部分：</p>
  <ul>
    <li><strong>Host（主机）代码：</strong>在 CPU 上运行的常规 C/C++ 代码。</li>
    <li><strong>Device（设备）代码：</strong>在 GPU 上运行的并行函数（核函数）。</li>
  </ul>

  <h2>二、关键语法元素</h2>

  <h3>1. 核函数 __global__</h3>
  <pre><code>__global__ void add(int *a, int *b, int *c) {
    int idx = threadIdx.x;
    c[idx] = a[idx] + b[idx];
}</code></pre>
  <p>调用方式：</p>
  <pre><code>add&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(a, b, c);</code></pre>

  <h3>2. 线程索引获取</h3>
  <pre><code>int idx = threadIdx.x + blockIdx.x * blockDim.x;</code></pre>

  <table>
    <thead>
      <tr><th>变量</th><th>说明</th></tr>
    </thead>
    <tbody>
      <tr><td>threadIdx.x</td><td>线程在 block 内的编号</td></tr>
      <tr><td>blockIdx.x</td><td>block 在 grid 中的编号</td></tr>
      <tr><td>blockDim.x</td><td>每个 block 的线程数</td></tr>
      <tr><td>gridDim.x</td><td>grid 中的 block 数</td></tr>
    </tbody>
  </table>

  <h2>三、内存管理</h2>

  <h3>1. 分配设备内存</h3>
  <pre><code>int *d_a;
cudaMalloc((void**)&d_a, N * sizeof(int));</code></pre>

  <h3>2. 拷贝数据</h3>
  <pre><code>cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice); // 主机到设备
cudaMemcpy(h_a, d_a, size, cudaMemcpyDeviceToHost); // 设备到主机</code></pre>

  <h3>3. 释放设备内存</h3>
  <pre><code>cudaFree(d_a);</code></pre>

  <h2>四、并行执行配置</h2>
  <p>调用核函数时通过 <code>&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;</code> 设置执行规模：</p>
  <pre><code>int blockSize = 256;
int gridSize = (N + blockSize - 1) / blockSize;
myKernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(args...);</code></pre>

  <h2>五、CUDA 内存类型</h2>
  <table>
    <thead>
      <tr><th>类型</th><th>说明</th><th>访问范围</th></tr>
    </thead>
    <tbody>
      <tr><td>Global Memory</td><td>全局大容量内存</td><td>所有线程可访问</td></tr>
      <tr><td>Shared Memory</td><td>同一个 block 的线程共享</td><td>block 内共享</td></tr>
      <tr><td>Local Memory</td><td>线程私有临时变量</td><td>线程私有</td></tr>
      <tr><td>Constant Memory</td><td>设备常量存储（只读）</td><td>所有线程可读</td></tr>
    </tbody>
  </table>

  <h2>六、常见 CUDA 工具函数</h2>
  <pre><code>cudaGetDeviceCount(&count);             // 获取 GPU 数量
cudaGetDeviceProperties(&prop, i);      // 获取第 i 个 GPU 属性
cudaSetDevice(i);                       // 选择使用的 GPU
cudaDeviceSynchronize();                // 同步 GPU 与 CPU 操作</code></pre>

  <h2>七、完整示例：向量加法</h2>
  <pre><code>__global__ void add(int *a, int *b, int *c) {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    c[i] = a[i] + b[i];
}

int main() {
    const int N = 512;
    int size = N * sizeof(int);

    int *h_a = (int*)malloc(size);
    int *h_b = (int*)malloc(size);
    int *h_c = (int*)malloc(size);

    for (int i = 0; i < N; i++) {
        h_a[i] = i;
        h_b[i] = i * 2;
    }

    int *d_a, *d_b, *d_c;
    cudaMalloc((void**)&d_a, size);
    cudaMalloc((void**)&d_b, size);
    cudaMalloc((void**)&d_c, size);

    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);

    add&lt;&lt;&lt;N/256, 256&gt;&gt;&gt;(d_a, d_b, d_c);

    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);

    for (int i = 0; i &lt; 10; i++) {
        printf("%d + %d = %d\n", h_a[i], h_b[i], h_c[i]);
    }

    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);
    free(h_a); free(h_b); free(h_c);
    return 0;
}</code></pre>

  <h2>总结</h2>
  <table>
    <thead>
      <tr><th>元素</th><th>说明</th></tr>
    </thead>
    <tbody>
      <tr><td><code>__global__</code></td><td>定义 GPU 核函数</td></tr>
      <tr><td><code>&lt;&lt;&lt;grid, block&gt;&gt;&gt;</code></td><td>指定并行执行规模</td></tr>
      <tr><td><code>threadIdx / blockIdx</code></td><td>索引计算唯一线程 ID</td></tr>
      <tr><td><code>cudaMalloc / cudaMemcpy / cudaFree</code></td><td>设备内存管理</td></tr>
    </tbody>
  </table>

</body>
</html>
